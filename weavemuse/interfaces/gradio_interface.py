"""
Gradio Interface - Web interface for the WeaveMuse Framework.
"""

import logging
import os, re, shutil
import tempfile
import threading
import glob
from typing import Optional, Tuple, Dict, Any, List
from pathlib import Path
import gradio as gr
import numpy as np
import soundfile as sf

from smolagents.agent_types import AgentAudio, AgentImage, AgentText
from smolagents.agents import MultiStepAgent, PlanningStep
from smolagents.memory import ActionStep, FinalAnswerStep
from smolagents.models import ChatMessageStreamDelta, MessageRole, agglomerate_stream_deltas
from smolagents.utils import _is_package_available
from smolagents.gradio_ui import stream_to_gradio

# Import the gradio_pdf component
try:
    from gradio_pdf import PDF
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("Warning: gradio_pdf not available. PDF viewer will be disabled.")

from ..agents.music_agent import MusicAgent
from ..utils.config import MusicAgentConfig

import logging
import os, re, shutil
import tempfile
from typing import Optional, Tuple, Dict, Any, List
from pathlib import Path
import gradio as gr
import numpy as np
import soundfile as sf

from smolagents.agent_types import AgentAudio, AgentImage, AgentText
from smolagents.agents import MultiStepAgent, PlanningStep
from smolagents.memory import ActionStep, FinalAnswerStep
from smolagents.models import ChatMessageStreamDelta, MessageRole, agglomerate_stream_deltas
from smolagents.utils import _is_package_available
from smolagents.gradio_ui import stream_to_gradio


logger = logging.getLogger(__name__)


class WeaveMuseInterface(gr.Blocks):
    """
    Gradio interface for interacting with a [`MultiStepAgent`], i.e. MusicAgent.

    This class provides a web interface to interact with the agent in real-time, allowing users to submit prompts, upload files, and receive responses in a chat-like format.
    It  can reset the agent's memory at the start of each interaction if desired.
    It supports file uploads, which are saved to a specified folder.
    It supports audio file playback for files uploaded by the user.
    It supports output audio playback for audio generated by the agent in a separate audio player.
    It uses the [`gradio.Chatbot`] component to display the conversation history.    
    This class requires the `gradio` extra to be installed: `smolagents[gradio]`.

    Args:
        agent ([`MultiStepAgent`]): The agent to interact with.
        file_upload_folder (`str`, *optional*): The folder where uploaded files will be saved.
            If not provided, file uploads are disabled.
        reset_agent_memory (`bool`, *optional*, defaults to `False`): Whether to reset the agent's memory at the start of each interaction.
            If `True`, the agent will not remember previous interactions.

    Raises:
        ModuleNotFoundError: If the `gradio` extra is not installed.

    Example:
        ```python
        from music_agent MusicAgent
        
        agent = MusicAgent(device="cuda:0")
        gradio_ui = GradioUI(agent, file_upload_folder="uploads", reset_agent_memory=True)
        gradio_ui.launch()
        ```
    """
    
    def __init__(self, agent: MultiStepAgent, file_upload_folder: str | None = None, reset_agent_memory: bool = False, **kwargs):
        self.agent = agent
        self.file_upload_folder = Path(file_upload_folder) if file_upload_folder is not None else None
        self.reset_agent_memory = reset_agent_memory
        self.name = "WeaveMuseInterface"
        self.description = getattr(agent, "description", None)
        
        # Add Gradio required attributes BEFORE calling super().__init__()
        self.state_session_capacity = 10000  # Default Gradio capacity
        
        # Session-wide generated files tracking
        self.session_generated_files = []
        
        if self.file_upload_folder is not None:
            if not self.file_upload_folder.exists():
                self.file_upload_folder.mkdir(parents=True, exist_ok=True)
        
        # Set default values for our custom arguments, but allow gradio to override them
        defaults = {
            "title": "WeaveMuse",
            "theme": "soft",
            "css": self._get_custom_css()
        }
        
        # Merge defaults with any kwargs passed from gradio app.py
        final_kwargs = {**defaults, **kwargs}
        
        # Initialize the parent class with all arguments
        super().__init__(**final_kwargs)

        self._create_app()

    def _create_app(self):        

        with self:            
            # Header
            gr.HTML("""
                <div class="main-header">
                    <h1>
                        <img class="logo" src="https://raw.githubusercontent.com/emmanouil-karystinaios/emmanouil-karystinaios.github.io/refs/heads/main/static/media/weave_muse_title.png" alt="WeaveMuse Logo"/>                         
                    </h1>
                    <p>AI-powered music understanding, generation, and analysis</p>
                </div>
            """)
            with gr.Tabs():
                with gr.Tab("Chat"):
                    self._create_chat_interface()
                with gr.Tab("About"):
                    self._create_about_interface()        

    def interact_with_agent(self, prompt, messages, session_state):        

        # Get the agent type from the template agent
        if "agent" not in session_state:
            session_state["agent"] = self.agent

        try:
            messages.append(gr.ChatMessage(role="user", content=prompt, metadata={"status": "done"}))
            yield messages

            for msg in stream_to_gradio(
                session_state["agent"], task=prompt, reset_agent_memory=self.reset_agent_memory
            ):
                if isinstance(msg, gr.ChatMessage):
                    messages[-1].metadata["status"] = "done"
                    messages.append(msg)
                elif isinstance(msg, str):  # Then it's only a completion delta
                    msg = msg.replace("<", r"\<").replace(">", r"\>")  # HTML tags seem to break Gradio Chatbot
                    if messages[-1].metadata["status"] == "pending":
                        messages[-1].content = msg
                    else:
                        messages.append(
                            gr.ChatMessage(role="assistant", content=msg, metadata={"status": "pending"})
                        )
                yield messages

            yield messages
        except Exception as e:
            yield messages
            raise gr.Error(f"Error in interaction: {str(e)}")

    def upload_file(self, file, file_uploads_log, allowed_file_types=None):
        """
        Upload a file and add it to the list of uploaded files in the session state.

        The file is saved to the `self.file_upload_folder` folder.
        If the file type is not allowed, it returns a message indicating the disallowed file type.

        Args:
            file (`gradio.File`): The uploaded file.
            file_uploads_log (`list`): A list to log uploaded files.
            allowed_file_types (`list`, *optional*): List of allowed file extensions. Defaults to [".pdf", ".docx", ".txt"].
        """
        import gradio as gr

        if file is None:
            return gr.Textbox(value="No file uploaded", visible=True), file_uploads_log

        if allowed_file_types is None:
            allowed_file_types = [".pdf", ".docx", ".txt"]

        file_ext = os.path.splitext(file.name)[1].lower()
        if file_ext not in allowed_file_types:
            return gr.Textbox("File type disallowed", visible=True), file_uploads_log

        # Sanitize file name
        original_name = os.path.basename(file.name)
        sanitized_name = re.sub(
            r"[^\w\-.]", "_", original_name
        )  # Replace any non-alphanumeric, non-dash, or non-dot characters with underscores

        # Save the uploaded file to the specified folder
        file_path = os.path.join(str(self.file_upload_folder), os.path.basename(sanitized_name))
        shutil.copy(file.name, file_path)

        return gr.Textbox(f"File uploaded: {file_path}", visible=True), file_uploads_log + [file_path]

    def log_user_message(self, text_input, file_uploads_log):
        import gradio as gr

        return (
            text_input
            + (
                f"\nYou have been provided with these files, which might be helpful or not: {file_uploads_log}"
                if len(file_uploads_log) > 0
                else ""
            ),
            "",
            gr.Button(interactive=False),
        )

    # def launch(self, share: bool = True, **kwargs):
    #     """
    #     Launch the Gradio app with the agent interface.

    #     Args:
    #         share (`bool`, defaults to `True`): Whether to share the app publicly.
    #         **kwargs: Additional keyword arguments to pass to the Gradio launch method.
    #     """
    #     self._create_app().launch(debug=True, share=share, **kwargs)

    def _get_custom_css(self) -> str:
        # Define custom CSS for better styling
        custom_css = """
        .main-header {
            text-align: center;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .tool-section {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        .chat-container {
            max-height: 500px;
            overflow-y: auto;
        }
        .logo {
            height: 2em;
            width: auto;            
            margin-inline: auto;
            display: block;            
        }
        /* Interrupt button styling */
        .stop-button {
            background-color: #ff4444 !important;
            color: white !important;
            border: 2px solid #cc0000 !important;
        }
        .stop-button:hover {
            background-color: #cc0000 !important;
            transform: scale(1.05);
        }
        /* Processing indicator styling */
        #processing-status {
            background: linear-gradient(90deg, #4CAF50, #45a049, #4CAF50);
            background-size: 200% 100%;
            animation: processing-animation 2s ease-in-out infinite;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            text-align: center;
            font-weight: bold;
        }
        @keyframes processing-animation {
            0% { background-position: 200% 0; }
            100% { background-position: -200% 0; }
        }
        """
        return custom_css

    def _extract_music_outputs(self, message):
        """Extract music generation outputs from agent message"""
        import gradio as gr
        import re
        import os
        import glob
        from datetime import datetime, timedelta
        
        content = message.content if hasattr(message, 'content') else str(message)
        logger.debug(f"Processing message content: {content[:200]}...")  # Show first 200 chars
        
        # Enhanced patterns to catch NotaGen file paths from various message formats
        notagen_patterns = [
            # Direct file paths - check both PDF and ABC files
            r'/tmp/notagen_output/[^\s\n,\'\"]+\.pdf',
            r'/tmp/notagen_output/[^\s\n,\'\"]+\.abc',
            r'/tmp/music_agent_audio/[^\s\n,\'\"]+\.pdf',
            # From agent responses and final answers
            r'Final answer:\s*/tmp/notagen_output/[^\s\n,\'\"]+\.(?:abc|pdf)',
            r'symbolic_music_agent.*?/tmp/notagen_output/[^\s\n,\'\"]+\.(?:abc|pdf)',
            # From logs and tool outputs
            r'\'pdf\':\s*\'([^\']+\.pdf)\'',
            r'"pdf":\s*"([^"]+\.pdf)"',
            r'\'abc\':\s*\'([^\']+\.abc)\'',
            r'"abc":\s*"([^"]+\.abc)"',
            r'ABC notation converted.*?\'pdf\':\s*\'([^\']+)\'',
            r'ABC notation converted.*?\'abc\':\s*\'([^\']+)\'',
            # Labeled outputs
            r'- PDF[:\s]+([^\s\n,\'\"]+\.pdf)',
            r'- ABC[:\s]+([^\s\n,\'\"]+\.abc)',
            r'PDF File[:\s]+([^\s\n,\'\"]+\.pdf)',
            r'ABC File[:\s]+([^\s\n,\'\"]+\.abc)',
            r'Generated.*?:\s*([^\s\n,\'\"]+\.(?:pdf|abc))',
        ]
        
        pdf_path = None
        abc_path = None
        found_explicit_file = False
        
        # Search for file paths in message content
        for pattern in notagen_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                potential_path = match.group(1) if match.lastindex and match.lastindex >= 1 else match.group(0)
                # Clean up the path (remove quotes, trailing characters)
                potential_path = potential_path.strip('\'".,')
                potential_path = re.sub(r'^Final answer:\s*', '', potential_path)
                
                logger.debug(f"Found potential path: {potential_path}")
                
                if os.path.exists(potential_path):
                    if potential_path.endswith('.pdf'):
                        pdf_path = potential_path
                        logger.debug(f"Found valid PDF: {pdf_path}")
                        break
                    elif potential_path.endswith('.abc'):
                        abc_path = potential_path
                        # Convert ABC path to PDF path
                        base_name = os.path.splitext(potential_path)[0]
                        potential_pdf = base_name + '.pdf'
                        if os.path.exists(potential_pdf):
                            pdf_path = potential_pdf
                            logger.debug(f"Found PDF from ABC: {pdf_path}")
                            break
                        else:
                            logger.debug(f"No PDF found for ABC file, will use ABC: {potential_path}")
                            # Store the ABC path for immediate use
                            abc_path = potential_path
                            # Mark that we found something to exit the pattern loop
                            found_explicit_file = True
                            # Break out of pattern search since we found a valid ABC file
                            break
            if pdf_path or found_explicit_file:
                break
        
        # If no explicit paths found but message indicates music generation, search for recent files
        if not pdf_path and self._is_music_generation_message(content):
            logger.debug("Music generation detected in message, searching for recent files...")
            pdf_path = self._find_recent_notagen_files()
            if pdf_path:
                logger.debug(f"Found recent NotaGen file: {pdf_path}")
            else:
                logger.debug("No recent PDF files found, searching for ABC files...")
                abc_path = self._find_recent_abc_files()
                if abc_path:
                    logger.debug(f"Found recent ABC file: {abc_path}")
        
        # If we have an ABC file but no PDF, try to find other formats or use ABC
        if abc_path and not pdf_path:
            logger.debug(f"Using ABC file as source: {abc_path}")
            base_name = os.path.splitext(abc_path)[0]
            
            # Try to find any associated files
            associated_files = []
            for ext in ['.pdf', '.xml', '.mid', '.mp3', '.png']:
                if ext == '.png':
                    # Look for page images
                    page_files = glob.glob(f"{base_name}_page_*.png")
                    associated_files.extend(page_files)
                else:
                    file_path = base_name + ext
                    if os.path.exists(file_path):
                        associated_files.append(file_path)
            
            logger.debug(f"Found {len(associated_files)} associated files for ABC")
            
            # If we found any associated files, create a minimal response
            if associated_files or abc_path:
                # Create download files list
                download_files_list = [abc_path] + associated_files
                
                # If there's a PDF in associated files, use it
                pdf_files = [f for f in associated_files if f.endswith('.pdf')]
                if pdf_files:
                    pdf_path = pdf_files[0]
                    logger.debug(f"Found PDF in associated files: {pdf_path}")
                
                # Return early with what we have
                pdf_info = None
                if pdf_path:
                    # Look for PNG images
                    png_images = [f for f in associated_files if f.endswith('.png')]
                    if png_images:
                        # Safe sorting by page number
                        def extract_page_num(filename):
                            match = re.search(r'page_(\d+)', filename)
                            return int(match.group(1)) if match else 0
                        
                        png_images.sort(key=extract_page_num)
                        pdf_info = {
                            'pdf_path': pdf_path,
                            'images': png_images,
                            'first_page': png_images[0] if png_images else None,
                            'pages': len(png_images),
                            'current_page': 1
                        }
                
                # Look for audio files
                audio_path = None
                audio_files = [f for f in associated_files if f.endswith(('.mp3', '.wav', '.flac', '.ogg', '.m4a'))]
                if audio_files:
                    audio_path = audio_files[0]
                    logger.debug(f"Found audio file: {audio_path}")
                
                return pdf_info, audio_path, download_files_list

        if pdf_path:
            # if we have a pdf then we check that it was generated recently
            # i.e. created in the last 10 minutes
            file_time = datetime.fromtimestamp(os.path.getctime(pdf_path))
            if file_time < datetime.now() - timedelta(minutes=10):
                logger.debug(f"PDF file {pdf_path} is too old ({file_time}), ignoring.")
                pdf_path = None
        
        if pdf_path:
            # Look for associated PNG images (NotaGen creates these)
            base_name = os.path.splitext(pdf_path)[0]
            png_images = glob.glob(f"{base_name}_page_*.png")
            
            # If no PNG images found, convert PDF to images
            if not png_images:
                png_images = self._pdf_to_images(pdf_path)
            
            if png_images:
                # Sort images by page number safely
                def extract_page_num(filename):
                    match = re.search(r'page_(\d+)', filename)
                    return int(match.group(1)) if match else 0
                
                png_images.sort(key=extract_page_num)
                
                pdf_info = {
                    'pdf_path': pdf_path,
                    'images': png_images,
                    'first_page': png_images[0],
                    'pages': len(png_images),
                    'current_page': 1
                }
                
                # Look for associated audio file
                audio_path = None
                audio_patterns = [
                    rf'{re.escape(base_name)}\.(?:wav|mp3|flac|ogg|m4a)',
                    r'/tmp/notagen_output/[^\s\n]+\.(?:wav|mp3|flac|ogg|m4a)',
                    r'/tmp/music_agent_audio/[^\s\n]+\.(?:wav|mp3|flac|ogg|m4a)',
                    r'- MP3[:\s]+([^\s\n]+\.(?:wav|mp3|flac|ogg|m4a))',
                    r'MP3 File[:\s]+([^\s\n]+\.(?:wav|mp3|flac|ogg|m4a))'
                ]
                
                for pattern in audio_patterns:
                    audio_match = re.search(pattern, content, re.IGNORECASE)
                    if audio_match:
                        potential_audio = audio_match.group(1) if audio_match.lastindex else audio_match.group(0)
                        if os.path.exists(potential_audio):
                            audio_path = potential_audio
                            break
                
                # If no audio found in message, look for audio file with same base name
                if not audio_path:
                    for ext in ['.mp3', '.wav', '.flac', '.ogg', '.m4a']:
                        potential_audio = base_name + ext
                        if os.path.exists(potential_audio):
                            audio_path = potential_audio
                            break
                
                # Collect download files
                download_files = []
                for ext in ['.pdf', '.xml', '.mid', '.wav', '.mp3', '.abc']:
                    file_path = base_name + ext
                    if os.path.exists(file_path):
                        download_files.append(file_path)
                
                return pdf_info, audio_path, download_files
        
        return None, None, None

    def _is_music_generation_message(self, content):
        """Check if the message indicates music generation has occurred"""
        generation_indicators = [
            # Music generation terms
            'piano piece',
            'composed',
            'generated',
            'notagen',
            'music generation',
            'musical composition',
            'score',
            'sheet music',
            'abc notation',
            'composition',
            # Composer names
            'chopin',
            'bach',
            'mozart',
            'beethoven',
            'debussy',
            'rachmaninoff',
            # Musical styles and periods
            'romantic',
            'classical',
            'baroque',
            'renaissance',
            'impressionist',
            'piece in the style',
            'mazurka',
            'waltz',
            'sonata',
            'prelude',
            'etude',
            # Tool-specific indicators
            'symbolic_music_agent',
            'successfully generated music composition',
            'generated files',
            '/tmp/notagen_output',
            '.abc',
            '.pdf',
            '.xml',
            '.mid',
            '.mp3',
            'final answer',
            'abc notation converted'
        ]
        
        content_lower = content.lower()
        has_indicator = any(indicator in content_lower for indicator in generation_indicators)
        
        if has_indicator:
            logger.debug("Music generation indicator found in message")
        
        return has_indicator

    def _find_recent_notagen_files(self):
        """Find the most recently created PDF file in NotaGen output directories"""
        import os
        import glob
        from datetime import datetime, timedelta
        
        search_dirs = ['/tmp/notagen_output/', '/tmp/music_agent_audio/']
        recent_files = []
        
        # Look for PDF files created in the last 10 minutes (increased from 5 minutes)
        cutoff_time = datetime.now() - timedelta(minutes=10)
        
        logger.debug(f"Searching for files newer than {cutoff_time}")
        
        for search_dir in search_dirs:
            if os.path.exists(search_dir):
                logger.debug(f"Searching in directory: {search_dir}")
                pdf_files = glob.glob(os.path.join(search_dir, '*.pdf'))
                logger.debug(f"Found {len(pdf_files)} PDF files in {search_dir}")
                
                for pdf_file in pdf_files:
                    try:
                        file_time = datetime.fromtimestamp(os.path.getctime(pdf_file))
                        logger.debug(f"File {os.path.basename(pdf_file)} created at {file_time}")
                        if file_time > cutoff_time:
                            recent_files.append((pdf_file, file_time))
                            logger.debug(f"Added {pdf_file} to recent files")
                        else:
                            logger.debug(f"File {pdf_file} too old ({file_time} < {cutoff_time})")
                    except OSError as e:
                        logger.debug(f"Error accessing {pdf_file}: {e}")
                        continue
            else:
                logger.debug(f"Directory {search_dir} does not exist")
        
        if recent_files:
            # Return the most recently created file
            recent_files.sort(key=lambda x: x[1], reverse=True)
            latest_file = recent_files[0][0]
            logger.debug(f"Returning most recent file: {latest_file}")
            return latest_file
        
        logger.debug("No recent files found")
        return None

    def _find_recent_abc_files(self):
        """Find the most recently created ABC file in NotaGen output directories"""
        import os
        import glob
        from datetime import datetime, timedelta
        
        search_dirs = ['/tmp/notagen_output/', '/tmp/music_agent_audio/']
        recent_files = []
        
        # Look for ABC files created in the last 10 minutes
        cutoff_time = datetime.now() - timedelta(minutes=10)
        
        logger.debug(f"Searching for ABC files newer than {cutoff_time}")
        
        for search_dir in search_dirs:
            if os.path.exists(search_dir):
                logger.debug(f"Searching in directory: {search_dir}")
                abc_files = glob.glob(os.path.join(search_dir, '*.abc'))
                logger.debug(f"Found {len(abc_files)} ABC files in {search_dir}")
                
                for abc_file in abc_files:
                    try:
                        file_time = datetime.fromtimestamp(os.path.getctime(abc_file))
                        logger.debug(f"ABC file {os.path.basename(abc_file)} created at {file_time}")
                        if file_time > cutoff_time:
                            recent_files.append((abc_file, file_time))
                            logger.debug(f"Added {abc_file} to recent ABC files")
                        else:
                            logger.debug(f"ABC file {abc_file} too old ({file_time} < {cutoff_time})")
                    except OSError as e:
                        logger.debug(f"Error accessing {abc_file}: {e}")
                        continue
            else:
                logger.debug(f"Directory {search_dir} does not exist")
        
        if recent_files:
            # Return the most recently created file
            recent_files.sort(key=lambda x: x[1], reverse=True)
            latest_file = recent_files[0][0]
            logger.debug(f"Returning most recent ABC file: {latest_file}")
            return latest_file
        
        logger.debug("No recent ABC files found")
        return None
    
    def _pdf_to_images(self, pdf_path):
        """Convert PDF to images for display"""
        try:
            try:
                import fitz  # PyMuPDF
            except ImportError:
                print("PyMuPDF not available for PDF to image conversion")
                return []
                
            doc = fitz.open(pdf_path)
            images = []
            base_name = os.path.splitext(pdf_path)[0]
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                # Render page to PNG with 2x scaling for better quality
                mat = fitz.Matrix(2.0, 2.0)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")
                
                # Save as file with page number
                img_path = f"{base_name}_page_{page_num + 1}.png"
                with open(img_path, "wb") as f:
                    f.write(img_data)
                images.append(img_path)
                
                # Clean up pixmap
                pix = None
            
            doc.close()
            return images
        except Exception as e:
            print(f"Error converting PDF to images: {e}")
            return []

    def _extract_audio_from_message(self, message):
        """Extract audio file path from agent message and determine if actions should be shown."""
        import re
        
        if not hasattr(message, 'content'):
            return None, False
            
        content = message.content
        
        # Check if content is AgentAudio type
        if isinstance(content, AgentAudio):
            # Try different possible audio attributes
            for attr in ['path', 'file_path', 'url', 'raw']:
                if hasattr(content, attr):
                    value = getattr(content, attr)
                    if attr == 'raw' and value is not None:
                        # Create temporary file for raw audio data
                        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                            sf.write(tmp_file.name, value, 22050)  # Default sample rate
                        return tmp_file.name, True
                    elif value and attr != 'raw':
                        return str(value), True
        
        # Check if content is string with audio file patterns
        elif isinstance(content, str):
            audio_patterns = [
                # Specific tool outputs
                r'/tmp/music_agent_audio/[^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a)',  # Specific tmp directory pattern
                r'/tmp/stable_audio/[^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a)',  # Stable audio output
                r'/tmp/audio_[^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a)',  # Generic tmp audio
                
                # Tool-specific patterns
                r'stable_audio_tool.*?([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'audio_generation_tool.*?([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'generated audio.*?([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                
                # Generic patterns
                r'audio.*?saved.*?to[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'generated.*?audio[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'output.*?file[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'created.*?audio[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'saved.*?to[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',  # Common save pattern
                r'audio file.*?[:\s]+([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',
                r'Final answer[:\s]*([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))',  # Final answer pattern
                r'([^\s\n,\'\"]+\.(?:wav|mp3|flac|ogg|m4a))'  # Generic audio file pattern (last resort)
            ]
            
            for pattern in audio_patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    if pattern.startswith(r'/tmp/'):
                        # Direct match for tmp directory files
                        audio_path = match.group(0)
                    else:
                        # Extract from capture group
                        audio_path = match.group(1) if match.lastindex and match.lastindex >= 1 else match.group(0)
                    
                    # Clean up the path
                    audio_path = audio_path.strip('\'".,;')
                    
                    if os.path.exists(audio_path):
                        logger.debug(f"Found audio file: {audio_path}")
                        return audio_path, True
                    else:
                        logger.debug(f"Audio file not found: {audio_path}")
        
        return None, False


    def _create_chat_interface(self):
        import gradio as gr
        
        # Session state to store audio files, conversation context, and music files
        session_state = gr.State({})
        stored_messages = gr.State([])
        uploaded_audio_files = gr.State([])
        pdf_state = gr.State({})  # For PDF page navigation
        session_generated_files = gr.State([])  # Track all generated files in session
        current_audio_path = gr.State(None)  # Keep track of current audio
        pdf_viewer_visible = gr.State(False)  # Track PDF viewer visibility
        current_pdf_path = gr.State(None)  # Track current PDF path
        
        with gr.Row():
            # Main chat area
            with gr.Column(scale=2):
                # Chat messages
                chatbot = gr.Chatbot(
                    label="🎵 Music Agent Chat",
                    type="messages",
                    height=400,  # Reduced to make room for other components
                    avatar_images=(
                        "https://raw.githubusercontent.com/manoskary/weavemuse/refs/heads/main/static/avatars/user_avatar.png",
                        "https://raw.githubusercontent.com/manoskary/weavemuse/refs/heads/main/static/avatars/agent_avatar.png",
                    ),
                    show_copy_button=True,
                    latex_delimiters=[
                        {"left": r"$$", "right": r"$$", "display": True},
                        {"left": r"$", "right": r"$", "display": False},
                        {"left": r"\[", "right": r"\]", "display": True},
                        {"left": r"\(", "right": r"\)", "display": False},
                    ],
                )
                
                # Progress indicator for tool/agent processing
                with gr.Row(visible=False) as progress_row:
                    progress_bar = gr.HTML("""
                    <div style="display: flex; align-items: center; justify-content: center; gap: 10px; 
                                background: linear-gradient(90deg, #4CAF50, #45a049, #4CAF50); 
                                background-size: 200% 100%; 
                                animation: processing-animation 2s ease-in-out infinite;
                                color: white; padding: 12px 20px; border-radius: 25px; 
                                font-weight: bold; margin: 10px 0;">
                        <div style="display: inline-block; width: 20px; height: 20px; 
                                    border: 3px solid #ffffff; border-radius: 50%; 
                                    border-top: 3px solid transparent; 
                                    animation: spin 1s linear infinite;"></div>
                        <span>🤖 Agent is thinking and using tools...</span>
                    </div>
                    <style>
                        @keyframes spin {
                            0% { transform: rotate(0deg); }
                            100% { transform: rotate(360deg); }
                        }
                        @keyframes processing-animation {
                            0% { background-position: 200% 0; }
                            100% { background-position: -200% 0; }
                        }
                    </style>
                    """)
                
                # PDF display area for sheet music
                with gr.Group(visible=False) as pdf_display_group:
                    with gr.Row():
                        gr.HTML("<h3>🎼 Generated Sheet Music</h3>")
                    
                    pdf_image = gr.Image(
                        label="Sheet Music Preview",
                        show_label=False,
                        height=400,
                        type="filepath",
                        interactive=False,
                        show_download_button=False
                    )
                    
                    # Page navigation
                    with gr.Row():
                        prev_btn = gr.Button("⬅️ Previous Page", variant="secondary", size="sm")
                        page_info = gr.HTML("<center>Page 1 of 1</center>")
                        next_btn = gr.Button("Next Page ➡️", variant="secondary", size="sm")
                
                # Audio output for generated music
                audio_output = gr.Audio(
                    label="🎵 Generated Audio",
                    type="filepath",
                    interactive=False,
                    visible=False
                )                                
                
                # Input area
                with gr.Row():
                    with gr.Column(scale=4):
                        text_input = gr.Textbox(
                            placeholder="Ask me anything about music, upload audio, or request compositions... \n Click the Send button or use CTRL+Shift.",
                            label="Ask me anything",
                            lines=2,
                            max_lines=5
                        )
                    with gr.Column(scale=1):
                        submit_btn = gr.Button("Send", variant="primary", size="lg")
                        interrupt_btn = gr.Button("⏹️ Stop", variant="stop", size="lg", visible=False, elem_classes=["stop-button"])
                        clear_btn = gr.Button("Clear Chat", variant="secondary", size="sm")
                
                # Audio upload and playback area
                with gr.Row():
                    with gr.Column():
                        audio_input = gr.Audio(
                            label="🎵 Upload Audio File",
                            type="filepath",
                            interactive=True
                        )
                        
                        # Display uploaded audio info
                        audio_info = gr.Textbox(
                            label="Uploaded Audio Info",
                            interactive=False,
                            visible=False
                        )
                        
                    with gr.Column():
                        # Agent-generated audio player
                        audio_output = gr.Audio(
                            label="🔊 Agent Generated Audio",
                            interactive=False,
                            visible=False
                        )
                        
                        # Quick actions for generated audio
                        with gr.Row(visible=False) as audio_actions:
                            analyze_generated_btn = gr.Button("🔍 Analyze This Audio", size="sm")
                            download_audio_btn = gr.Button("💾 Download", size="sm")
            
            # Sidebar with tools and examples
            with gr.Column(scale=1):
                # gr.Markdown("### 🎵 Music Agent")
                # gr.Markdown("Your AI assistant for music creation, analysis, and understanding.")
                
                # Audio management
                with gr.Group():
                    gr.Markdown("**🎵 Audio Files**")
                    audio_list = gr.Textbox(
                        label="Uploaded Files",
                        value="No audio files uploaded",
                        interactive=False,
                        max_lines=3
                    )
                    clear_audio_btn = gr.Button("Clear Audio Files", size="sm", variant="secondary")
                
                # Quick actions
                # with gr.Group():
                #     gr.Markdown("**⚡ Quick Actions**")
                    
                #     quick_compose_btn = gr.Button("🎼 Compose Music", variant="secondary")
                #     quick_analyze_btn = gr.Button("🔍 Analyze Audio", variant="secondary")
                #     quick_theory_btn = gr.Button("📚 Music Theory", variant="secondary")
                #     quick_generate_btn = gr.Button("🎵 Generate Audio", variant="secondary")
                
                # Example prompts
                with gr.Group():
                    gr.Markdown("**💡 Example Prompts**")
                    examples = [
                        "Compose a peaceful piano piece in the style of Chopin",
                        "Analyze the harmony in my uploaded audio",
                        "Generate upbeat elevator music",
                        "Explain what musical scales are and how they work",
                        # "Generate ambient music for relaxation",                        
                    ]
                    
                    for example in examples:
                        gr.Button(
                            example,
                            variant="secondary", 
                            size="sm"
                        ).click(
                            lambda x=example: x,
                            outputs=text_input
                        )
                
                # Audio help
                with gr.Group():
                    gr.Markdown("**🎧 Audio Support**")
                    gr.Markdown("""
                    **Supported formats:**
                    - WAV, MP3, FLAC, OGG
                    - Max duration: 10 minutes
                    - Sample rates: 16kHz - 48kHz
                    
                    """)

                    # Audio features not used text maybe usefull in the future
                    """
                    **Features:**
                    - Upload multiple audio files
                    - Real-time playback
                    - Audio analysis
                    - Generate music from descriptions
                    """

                # Download files section - Make it always visible but contents conditional
                with gr.Group():
                    gr.HTML("<h4>📁 Download Generated Files</h4>")
                    download_files = gr.Files(
                        label="Generated Files (PDF, Audio, MIDI, etc.)",
                        type="filepath",
                        visible=True,
                        allow_reordering=True,
                        interactive=True,
                        
                    )
                
                # PDF Viewer section - Only visible when PDF is generated
                with gr.Group(visible=False) as pdf_viewer_group:
                    gr.HTML("<h4>📄 Sheet Music PDF</h4>")
                    
                    # Use gradio_pdf's PDF component for proper PDF viewing
                    if PDF_AVAILABLE:
                        from gradio_pdf import PDF
                        pdf_viewer = PDF(
                            label="Generated Sheet Music",
                            height=400,
                            visible=True,
                            interactive=True
                        )
                    else:
                        # Fallback to regular File component if gradio_pdf not available
                        print("Warning: Using File component as fallback - gradio_pdf not available")
                        pdf_viewer = gr.File(
                            label="Click to view Sheet Music PDF",
                            type="filepath",
                            height=300,
                            visible=True,
                            interactive=False,
                            show_label=True
                        )
                    
                    # Add buttons for PDF actions
                    with gr.Row():
                        open_pdf_btn = gr.Button("🔍 Open PDF in New Tab", variant="primary", size="sm")
                        download_pdf_btn = gr.Button("💾 Download PDF", variant="secondary", size="sm")

        # Enhanced audio file handler
        def handle_audio_upload(audio_file, current_files, audio_list_text):
            if audio_file is None:
                return current_files, audio_list_text, gr.Textbox(visible=False)
            
            # Save uploaded file
            if self.file_upload_folder:
                filename = os.path.basename(audio_file)
                saved_path = os.path.join(self.file_upload_folder, filename)
                shutil.copy(audio_file, saved_path)
                
                # Update file list
                new_files = current_files + [saved_path]
                
                # Get audio info
                try:
                    import librosa
                    y, sr = librosa.load(saved_path, sr=None)
                    duration = len(y) / sr
                    audio_info_text = f"📁 {filename}\n⏱️ Duration: {duration:.2f}s\n🔊 Sample Rate: {sr}Hz"
                except:
                    audio_info_text = f"📁 {filename}\n✅ Uploaded successfully"
                
                # Update audio list display
                file_list = "Uploaded Audio Files:\n" + "\n".join([f"• {os.path.basename(f)}" for f in new_files])
                
                return new_files, file_list, gr.Textbox(value=audio_info_text, visible=True)
            
            return current_files, audio_list_text, gr.Textbox(visible=False)

        # Enhanced message handler with audio context
        def log_user_message_with_audio(text_input, audio_files):
            import gradio as gr
            
            # Prepare message with audio context
            message = text_input
            if audio_files:
                audio_context = f"\n\nUploaded audio files: {', '.join([os.path.basename(f) for f in audio_files])}"
                message += audio_context
            
            return (
                message,
                "",  # Clear text input
                gr.Button(interactive=False),  # Disable submit button
            )

        # Enhanced agent interaction with audio and PDF handling
        def interact_with_agent_enhanced(prompt, messages, session_state, audio_files, session_files, current_audio, pdf_visible, current_pdf, interrupt_flag=None):
            import gradio as gr
            import time
            
            # Initialize interrupt flag if not provided
            if interrupt_flag is None:
                interrupt_flag = {"interrupted": False}
            
            # Store audio files in session state
            if "audio_files" not in session_state:
                session_state["audio_files"] = []
            session_state["audio_files"].extend(audio_files)
            
            # Store interrupt flag in session state
            session_state["interrupt_flag"] = interrupt_flag
            
            # Get the agent from session state
            if "agent" not in session_state:
                session_state["agent"] = self.agent

            # Initialize variables
            notagen_audio_found = False  # Track if we found NotaGen audio
            latest_audio_path = current_audio  # Keep track of current audio               

            try:
                messages.append(gr.ChatMessage(role="user", content=prompt, metadata={"status": "done"}))
                # Show processing status and retain current audio, show interrupt button
                yield (messages, 
                       gr.Audio(value=current_audio, visible=bool(current_audio)), 
                       gr.Row(visible=bool(current_audio)), 
                       gr.Files(value=session_files, visible=True), 
                       gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                       gr.File(value=current_pdf, visible=bool(current_pdf)), 
                       gr.Row(visible=True),  # Show processing indicator
                       gr.Button(visible=False),  # Hide submit button
                       gr.Button(visible=True),   # Show interrupt button
                       session_files,  # Return session files to maintain state
                       current_audio,  # Return current audio to maintain state
                       pdf_visible,  # Return PDF visibility state
                       current_pdf)  # Return current PDF path
                
                for msg in stream_to_gradio(
                    session_state["agent"], task=prompt, reset_agent_memory=self.reset_agent_memory
                ):
                    # Check for interrupt
                    if interrupt_flag["interrupted"]:
                        # Add interruption message
                        messages.append(gr.ChatMessage(
                            role="assistant", 
                            content="⏹️ **Generation interrupted by user.**", 
                            metadata={"status": "done"}
                        ))
                        yield (messages, 
                               gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                               gr.Row(visible=bool(latest_audio_path)),
                               gr.Files(value=session_files, visible=True),
                               gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                               gr.File(value=current_pdf, visible=bool(current_pdf)),
                               gr.Row(visible=False),  # Hide processing indicator
                               gr.Button(visible=True, interactive=True),  # Show submit button
                               gr.Button(visible=False, interactive=False),  # Hide interrupt button
                               session_files,  # Return session files to maintain state
                               latest_audio_path,  # Return current audio to maintain state
                               pdf_visible,  # Return PDF visibility state
                               current_pdf)  # Return current PDF path
                        return
                    
                    if isinstance(msg, gr.ChatMessage):
                        messages[-1].metadata["status"] = "done"
                        messages.append(msg)
                        
                        # Check for music generation outputs (NotaGen)
                        pdf_info, audio_path, download_files_list = self._extract_music_outputs(msg)
                        
                        logger.debug(f"Extraction results - PDF: {bool(pdf_info)}, Audio: {bool(audio_path)}, Files: {len(download_files_list) if download_files_list else 0}")
                        if download_files_list:
                            logger.debug(f"Download files: {download_files_list}")
                            # Add new files to session generated files
                            for file_path in download_files_list:
                                if file_path not in session_files:
                                    session_files.append(file_path)
                        
                        if pdf_info:
                            # Add image to the message content using proper file path for Gradio
                            original_content = msg.content if hasattr(msg, 'content') else str(msg)
                            if pdf_info.get('first_page'):
                                # Get the image path and ensure it's accessible by Gradio
                                image_path = pdf_info.get('first_page')
                                logger.debug(f"Embedding image in message: {image_path}")
                                
                                # For Gradio ChatInterface, we need to provide a simple text message
                                # The image will be handled separately by the download files
                                modified_content = f"{original_content}\n\n📄 **Generated Sheet Music** (3 pages)\n💾 Check the download files below for complete score and audio"
                                
                                # Update the message content
                                if hasattr(msg, 'content'):
                                    msg.content = modified_content
                                else:
                                    messages[-1] = gr.ChatMessage(
                                        role="assistant", 
                                        content=modified_content, 
                                        metadata={"status": "done"}
                                    )
                            
                            # Mark that we found NotaGen audio and update current audio
                            if audio_path:
                                notagen_audio_found = True
                                latest_audio_path = audio_path
                                logger.debug(f"NotaGen audio found: {audio_path}")
                            
                            # Find PDF file for the viewer
                            pdf_file_path = None
                            if download_files_list:
                                pdf_files = [f for f in download_files_list if f.endswith('.pdf')]
                                if pdf_files:
                                    pdf_file_path = pdf_files[0]  # Use the first PDF file
                                    logger.debug(f"PDF file for viewer: {pdf_file_path}")
                                    # Update PDF state when PDF is found
                                    pdf_visible = True
                                    current_pdf = pdf_file_path
                            
                            # Prioritize NotaGen audio over generic generated audio
                            yield (messages, 
                                   gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                                   gr.Row(visible=bool(latest_audio_path)),
                                   gr.Files(value=session_files, visible=True),
                                   gr.Group(visible=pdf_visible), # Show PDF viewer if PDF exists
                                   gr.File(value=current_pdf, visible=bool(current_pdf)),
                                   gr.Row(visible=True),  # Keep processing indicator visible
                                   gr.Button(visible=False),  # Hide submit button
                                   gr.Button(visible=True),   # Show interrupt button
                                   session_files,  # Return session files to maintain state
                                   latest_audio_path,  # Return current audio to maintain state
                                   pdf_visible,  # Return PDF visibility state
                                   current_pdf)  # Return current PDF path
                        else:
                            # Check for regular audio content
                            audio_path, show_actions = self._extract_audio_from_message(msg)
                            if audio_path:
                                if audio_path not in session_files:
                                    session_files.append(audio_path)
                                latest_audio_path = audio_path
                                yield (messages, 
                                       gr.Audio(value=latest_audio_path, visible=True), 
                                       gr.Row(visible=show_actions),
                                       gr.Files(value=session_files, visible=True),
                                       gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                                       gr.File(value=current_pdf, visible=bool(current_pdf)),
                                       gr.Row(visible=True),  # Keep processing indicator visible
                                       gr.Button(visible=False),  # Hide submit button
                                       gr.Button(visible=True),   # Show interrupt button
                                       session_files,  # Return session files to maintain state
                                       latest_audio_path,  # Return current audio to maintain state
                                       pdf_visible,  # Return PDF visibility state
                                       current_pdf)  # Return current PDF path
                            else:
                                yield (messages, 
                                       gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                                       gr.Row(visible=bool(latest_audio_path)),
                                       gr.Files(value=session_files, visible=True),
                                       gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                                       gr.File(value=current_pdf, visible=bool(current_pdf)),
                                       gr.Row(visible=True),  # Keep processing indicator visible
                                       gr.Button(visible=False),  # Hide submit button
                                       gr.Button(visible=True),   # Show interrupt button
                                       session_files,  # Return session files to maintain state
                                       latest_audio_path,  # Return current audio to maintain state
                                       pdf_visible,  # Return PDF visibility state
                                       current_pdf)  # Return current PDF path
                            
                    elif isinstance(msg, str):
                        msg = msg.replace("<", r"\<").replace(">", r"\>")
                        if messages[-1].metadata["status"] == "pending":
                            messages[-1].content = msg
                        else:
                            messages.append(
                                gr.ChatMessage(role="assistant", content=msg, metadata={"status": "pending"})
                            )
                        
                        # Check partial messages for music outputs
                        yield (messages, 
                               gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                               gr.Row(visible=bool(latest_audio_path)),
                               gr.Files(value=session_files, visible=True),
                               gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                               gr.File(value=current_pdf, visible=bool(current_pdf)),
                               gr.Row(visible=True),  # Keep processing indicator visible
                               gr.Button(visible=False),  # Hide submit button
                               gr.Button(visible=True),   # Show interrupt button
                               session_files,  # Return session files to maintain state
                               latest_audio_path,  # Return current audio to maintain state
                               pdf_visible,  # Return PDF visibility state
                               current_pdf)  # Return current PDF path

                # Final check for any generated audio files (including stable_audio)
                if not notagen_audio_found:
                    # Check multiple possible audio directories
                    search_dirs = ["/tmp/music_agent_audio/", "/tmp/stable_audio/", "/tmp/", "/tmp/audio/"]
                    found_audio = None
                    
                    for search_dir in search_dirs:
                        if os.path.exists(search_dir):
                            audio_files_in_dir = []
                            try:
                                # Look for audio files in this directory
                                for f in os.listdir(search_dir):
                                    if f.endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):
                                        full_path = os.path.join(search_dir, f)
                                        # Check if file was created recently (within last 10 minutes)
                                        try:
                                            file_time = os.path.getctime(full_path)
                                            current_time = time.time()
                                            if current_time - file_time < 600:  # 10 minutes
                                                audio_files_in_dir.append(full_path)
                                        except OSError:
                                            continue
                                
                                if audio_files_in_dir:
                                    # Get the most recent file
                                    latest_audio = max(audio_files_in_dir, key=os.path.getctime)
                                    if latest_audio not in session_files:
                                        session_files.append(latest_audio)
                                    latest_audio_path = latest_audio
                                    found_audio = latest_audio
                                    logger.debug(f"Found audio file in {search_dir}: {latest_audio}")
                                    break  # Found audio, stop searching
                            except OSError as e:
                                logger.debug(f"Error accessing {search_dir}: {e}")
                                continue
                    
                    if found_audio:
                        logger.debug(f"Using fallback audio: {found_audio}")
                
                # Final yield with processing complete - show submit button, hide interrupt button
                yield (messages, 
                       gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                       gr.Row(visible=bool(latest_audio_path)), 
                       gr.Files(value=session_files, visible=True), 
                       gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                       gr.File(value=current_pdf, visible=bool(current_pdf)), 
                       gr.Row(visible=False),   # Hide processing indicator
                       gr.Button(visible=True, interactive=True),  # Show submit button
                       gr.Button(visible=False, interactive=False),  # Hide interrupt button
                       session_files,  # Return session files to maintain state
                       latest_audio_path,  # Return current audio to maintain state
                       pdf_visible,  # Return PDF visibility state
                       current_pdf)  # Return current PDF path
                
            except Exception as e:
                yield (messages, 
                       gr.Audio(value=latest_audio_path, visible=bool(latest_audio_path)), 
                       gr.Row(visible=bool(latest_audio_path)), 
                       gr.Files(value=session_files, visible=True), 
                       gr.Group(visible=pdf_visible),  # Maintain PDF viewer visibility
                       gr.File(value=current_pdf, visible=bool(current_pdf)), 
                       gr.Row(visible=False),   # Hide processing indicator
                       gr.Button(visible=True, interactive=True, variant="primary", size="lg"),  # Show submit button
                       gr.Button(visible=False, variant="secondary", size="lg"),  # Hide interrupt button
                       session_files,  # Return session files to maintain state
                       latest_audio_path,  # Return current audio to maintain state
                       pdf_visible,  # Return PDF visibility state
                       current_pdf)  # Return current PDF path
                raise gr.Error(f"Error in interaction: {str(e)}")

        # Clear functions - updated to handle new states
        def clear_chat():
            return [], gr.Audio(value=None, visible=False), gr.Row(visible=False), gr.Files(value=[], visible=True), gr.Group(visible=False), gr.File(visible=False), gr.Row(visible=False), gr.Button(visible=True, interactive=True), gr.Button(visible=False), [], None, False, None
        
        def clear_audio_files():
            return [], "No audio files uploaded", gr.Textbox(visible=False)

        # Quick action functions
        def set_compose_prompt():
            return "Compose an original piece of music. Please specify the style, instrumentation, and mood you'd like."
        
        def set_analyze_prompt():
            return "Please analyze the uploaded audio file. Include information about tempo, key, harmony, and musical structure."
        
        def set_theory_prompt():
            return "Explain a music theory concept. What would you like to learn about?"
        
        def set_generate_prompt():
            return "Generate audio from a text description. Describe the music you want to hear."

        # Event handlers
        audio_input.change(
            handle_audio_upload,
            inputs=[audio_input, uploaded_audio_files, audio_list],
            outputs=[uploaded_audio_files, audio_list, audio_info]
        )
        
        # Shared interrupt flag for the session
        interrupt_flag = gr.State({"interrupted": False})
        
        # Interrupt function
        def interrupt_agent(session_state):
            if "interrupt_flag" in session_state:
                session_state["interrupt_flag"]["interrupted"] = True
            return (
                gr.Button(visible=True, interactive=True),   # Show submit button
                gr.Button(visible=False, interactive=False)   # Hide interrupt button
            )
        
        # Submit handlers
        def start_interaction(text, audio_files, session_state, session_files, current_audio, pdf_visible, current_pdf, interrupt_flag):
            # Reset interrupt flag
            interrupt_flag["interrupted"] = False
            # Store the interrupt flag in session state for the interaction function
            session_state["interrupt_flag"] = interrupt_flag
            return log_user_message_with_audio(text, audio_files)
        
        # Submit event for text input
        submit_event = text_input.submit(
            start_interaction,
            inputs=[text_input, uploaded_audio_files, session_state, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path, interrupt_flag],
            outputs=[stored_messages, text_input, submit_btn],
        )
        submit_event.then(
            interact_with_agent_enhanced,
            inputs=[stored_messages, chatbot, session_state, uploaded_audio_files, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path, interrupt_flag],
            outputs=[chatbot, audio_output, audio_actions, download_files, pdf_viewer_group, pdf_viewer, progress_row, submit_btn, interrupt_btn, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path]
        )

        # Submit button click event
        click_event = submit_btn.click(
            start_interaction,
            inputs=[text_input, uploaded_audio_files, session_state, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path, interrupt_flag],
            outputs=[stored_messages, text_input, submit_btn],
        )
        click_event.then(
            interact_with_agent_enhanced,
            inputs=[stored_messages, chatbot, session_state, uploaded_audio_files, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path, interrupt_flag],
            outputs=[chatbot, audio_output, audio_actions, download_files, pdf_viewer_group, pdf_viewer, progress_row, submit_btn, interrupt_btn, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path]
        )
        
        # Interrupt handler
        interrupt_btn.click(
            interrupt_agent,
            inputs=[session_state],
            outputs=[submit_btn, interrupt_btn]
        )
        
        # Clear handlers - updated to handle new states
        clear_btn.click(clear_chat, outputs=[chatbot, audio_output, audio_actions, download_files, pdf_viewer_group, pdf_viewer, progress_row, submit_btn, interrupt_btn, session_generated_files, current_audio_path, pdf_viewer_visible, current_pdf_path])
        clear_audio_btn.click(clear_audio_files, outputs=[uploaded_audio_files, audio_list, audio_info])
        
        # PDF viewer handlers - improved functionality
        def open_pdf_in_new_tab(current_pdf_path):
            """Open PDF in new tab using JavaScript"""
            if current_pdf_path and os.path.exists(current_pdf_path):
                # Return JavaScript to open PDF in new tab
                return f"""
                <script>
                window.open('/file={current_pdf_path}', '_blank');
                </script>
                <p>Opening PDF in new tab...</p>
                """
            else:
                return "No PDF file available to open."
        
        def download_current_pdf(current_pdf_path):
            """Provide download functionality for current PDF"""
            if current_pdf_path and os.path.exists(current_pdf_path):
                # Return the PDF file for download
                return gr.File(value=current_pdf_path, visible=True, label="Download PDF")
            else:
                return gr.File(visible=False)
        
        # Update button handlers with improved functionality
        open_pdf_btn.click(
            open_pdf_in_new_tab,
            inputs=[current_pdf_path],
            outputs=[progress_bar]
        )
        
        download_pdf_btn.click(
            download_current_pdf,
            inputs=[current_pdf_path],
            outputs=[download_files]  # Add to the download files area
        )
        
        # Quick action handlers (commented out since buttons are commented out)
        # quick_compose_btn.click(set_compose_prompt, outputs=text_input)
        # quick_analyze_btn.click(set_analyze_prompt, outputs=text_input)
        # quick_theory_btn.click(set_theory_prompt, outputs=text_input)
        # quick_generate_btn.click(set_generate_prompt, outputs=text_input)
        
        # Audio action handlers
        def analyze_generated_audio(current_audio_path):
            """Analyze the currently generated audio if available"""
            if current_audio_path and os.path.exists(current_audio_path):
                return f"Analyze the audio that was just generated at: {current_audio_path}. What are its musical characteristics, genre, tempo, key, and overall structure?"
            else:
                return ""  # Return empty string if no audio available
        
        def download_generated_audio(current_audio_path):
            """Provide download functionality for generated audio"""
            if current_audio_path and os.path.exists(current_audio_path):
                # Return a file download component
                return gr.File(value=current_audio_path, visible=True, label="Download Generated Audio")
            else:
                # Return empty file component if no audio available
                return gr.File(visible=False)
        
        analyze_generated_btn.click(
            analyze_generated_audio,
            inputs=[current_audio_path],
            outputs=[text_input]
        )
        
        download_audio_btn.click(
            download_generated_audio,
            inputs=[current_audio_path],
            outputs=[download_files]  # Add to the download files area
        )
        
        # PDF navigation functions
        def navigate_pdf(direction, pdf_state):
            if not pdf_state or 'images' not in pdf_state:
                return gr.Image(value=None), gr.HTML("")
            
            current_page = pdf_state.get('current_page', 1)
            total_pages = pdf_state.get('pages', 1)
            
            if direction == "prev" and current_page > 1:
                current_page -= 1
            elif direction == "next" and current_page < total_pages:
                current_page += 1
            
            pdf_state['current_page'] = current_page
            new_image = pdf_state['images'][current_page - 1]
            page_info = f"<center>Page {current_page} of {total_pages}</center>"
            
            return gr.Image(value=new_image), gr.HTML(page_info)

        # Connect PDF navigation
        prev_btn.click(
            lambda pdf_state: navigate_pdf("prev", pdf_state),
            inputs=[pdf_state],
            outputs=[pdf_image, page_info]
        )
        
        next_btn.click(
            lambda pdf_state: navigate_pdf("next", pdf_state),
            inputs=[pdf_state],
            outputs=[pdf_image, page_info]
        )
    # def _create_chat_interface(self):
    #     """Create the chat interface tab."""
    #     gr.Markdown("## Chat with the Music Agent")
    #     gr.Markdown("Ask questions about music, request compositions, or analyze audio files.")
        
    #     with gr.Row():
    #         with gr.Column(scale=3):
    #             chatbot = gr.Chatbot(
    #                 height=400,
    #                 label="Music Agent Chat",
    #                 elem_classes=["chat-container"]
    #             )
                
    #             with gr.Row():
    #                 msg = gr.Textbox(
    #                     placeholder="Ask me anything about music...",
    #                     label="Your message",
    #                     scale=4
    #                 )
    #                 submit_btn = gr.Button("Send", variant="primary", scale=1)
                
    #             with gr.Row():
    #                 audio_input = gr.Audio(
    #                     label="Upload audio file (optional)",
    #                     type="filepath"
    #                 )
    #                 clear_btn = gr.Button("Clear Chat", variant="secondary")
            
    #         with gr.Column(scale=1):
    #             gr.Markdown("### 💡 Example Prompts")
    #             examples = [
    #                 "Compose a peaceful piano piece in C major",
    #                 "Analyze the harmony in this audio file",
    #                 "Generate a jazz composition for saxophone",
    #                 "Explain the difference between major and minor scales",
    #                 "Create ABC notation for a simple melody",
    #                 "What genre is this music?"
    #             ]
                
    #             for example in examples:
    #                 gr.Button(
    #                     example,
    #                     variant="outline",
    #                     size="sm"
    #                 ).click(
    #                     lambda x=example: x,
    #                     outputs=msg
    #                 )
        
    #     # Event handlers
    #     def respond(message: str, history: List, audio_file: Optional[str]):
    #         if self.agent is None:
    #             bot_response = "Music agent is not available. Please check the configuration."
    #         else:
    #             try:
    #                 bot_response = self.agent.run(message, audio_file=audio_file)
    #             except Exception as e:
    #                 bot_response = f"Error: {str(e)}"
            
    #         history.append((message, bot_response))
    #         return history, ""
        
    #     submit_btn.click(
    #         respond,
    #         inputs=[msg, chatbot, audio_input],
    #         outputs=[chatbot, msg]
    #     )
        
    #     msg.submit(
    #         respond,
    #         inputs=[msg, chatbot, audio_input],
    #         outputs=[chatbot, msg]
    #     )
        
    #     clear_btn.click(lambda: [], outputs=chatbot)
    
    # def _create_generation_interface(self):
    #     """Create the music generation interface."""
    #     gr.Markdown("## Generate Music")
    #     gr.Markdown("Create original music compositions using AI.")
        
    #     with gr.Row():
    #         with gr.Column():
    #             prompt = gr.Textbox(
    #                 label="Music Description",
    #                 placeholder="Describe the music you want to generate...",
    #                 lines=3
    #             )
                
    #             with gr.Row():
    #                 style = gr.Dropdown(
    #                     choices=["Classical", "Jazz", "Rock", "Folk", "Electronic", "Ambient"],
    #                     label="Style",
    #                     value="Classical"
    #                 )
                    
    #                 instrumentation = gr.Dropdown(
    #                     choices=["Piano", "Orchestra", "Guitar", "Violin", "Saxophone", "Mixed"],
    #                     label="Instrumentation",
    #                     value="Piano"
    #                 )
                
    #             with gr.Row():
    #                 output_format = gr.Radio(
    #                     choices=["ABC Notation", "Audio", "Both"],
    #                     label="Output Format",
    #                     value="ABC Notation"
    #                 )
                    
    #                 length = gr.Slider(
    #                     minimum=5,
    #                     maximum=60,
    #                     value=20,
    #                     step=5,
    #                     label="Duration (seconds)"
    #                 )
                
    #             generate_btn = gr.Button("Generate Music", variant="primary")
            
    #         with gr.Column():
    #             output_text = gr.Textbox(
    #                 label="Generated Content",
    #                 lines=15,
    #                 interactive=False
    #             )
                
    #             output_audio = gr.Audio(
    #                 label="Generated Audio",
    #                 type="filepath"
    #             )
                
    #             sheet_music = gr.Image(
    #                 label="Sheet Music",
    #                 type="filepath"
    #             )
        
    #     def generate_music(prompt, style, instrumentation, output_format, length):
    #         if self.agent is None:
    #             return "Music agent not available", None, None
            
    #         try:
    #             # Prepare generation parameters
    #             full_prompt = f"Generate a {style.lower()} piece for {instrumentation.lower()}: {prompt}"
                
    #             if output_format == "ABC Notation":
    #                 result = self.agent.generate_music(
    #                     full_prompt, 
    #                     style=style, 
    #                     instrumentation=instrumentation,
    #                     output_format="abc"
    #                 )
    #                 return result, None, None
                    
    #             elif output_format == "Audio":
    #                 audio_path = self.agent.generate_music(
    #                     full_prompt,
    #                     style=style,
    #                     instrumentation=instrumentation, 
    #                     output_format="audio"
    #                 )
    #                 return f"Audio generated: {audio_path}", audio_path, None
                    
    #             else:  # Both
    #                 abc_result = self.agent.generate_music(
    #                     full_prompt,
    #                     style=style,
    #                     instrumentation=instrumentation,
    #                     output_format="abc" 
    #                 )
                    
    #                 # Also generate audio
    #                 audio_path = self.agent.generate_music(
    #                     full_prompt,
    #                     style=style,
    #                     instrumentation=instrumentation,
    #                     output_format="audio"
    #                 )
                    
    #                 return abc_result, audio_path, None
                    
    #         except Exception as e:
    #             return f"Error generating music: {str(e)}", None, None
        
    #     generate_btn.click(
    #         generate_music,
    #         inputs=[prompt, style, instrumentation, output_format, length],
    #         outputs=[output_text, output_audio, sheet_music]
    #     )
    
    def _create_analysis_interface(self):
        """Create the audio analysis interface."""
        gr.Markdown("## Analyze Audio")
        gr.Markdown("Upload audio files for comprehensive musical analysis.")
        
        with gr.Row():
            with gr.Column():
                audio_input = gr.Audio(
                    label="Upload Audio File",
                    type="filepath"
                )
                
                analysis_type = gr.Radio(
                    choices=["Basic", "Detailed", "Harmonic", "Rhythmic", "Structure"],
                    label="Analysis Type",
                    value="Detailed"
                )
                
                analyze_btn = gr.Button("Analyze Audio", variant="primary")
            
            with gr.Column():
                analysis_output = gr.Textbox(
                    label="Analysis Results",
                    lines=20,
                    interactive=False
                )
        
        def analyze_audio(audio_file, analysis_type):
            if self.agent is None:
                return "Music agent not available"
            
            if audio_file is None:
                return "Please upload an audio file"
            
            try:
                # Use the agent's run method with a prompt for audio analysis
                prompt = f"Please analyze this audio file using {analysis_type.lower()} analysis. The audio file is at: {audio_file}"
                result = self.agent.run(prompt)
                return result
            except Exception as e:
                return f"Error analyzing audio: {str(e)}"
        
        analyze_btn.click(
            analyze_audio,
            inputs=[audio_input, analysis_type],
            outputs=analysis_output
        )
    
    def _create_tools_interface(self):
        """Create the music tools interface."""
        gr.Markdown("## Music Tools")
        gr.Markdown("Individual tools for specific music tasks.")
        
        with gr.Tabs():
            # ABC to Sheet Music
            with gr.Tab("🎼 ABC to Sheet Music"):
                with gr.Row():
                    abc_input = gr.Textbox(
                        label="ABC Notation",
                        placeholder="Enter ABC notation here...",
                        lines=10
                    )
                    
                    render_btn = gr.Button("Render Sheet Music", variant="primary")
                
                sheet_output = gr.Image(label="Sheet Music")
                
                def render_abc(abc_notation):
                    if self.agent is None:
                        return None
                    
                    try:
                        # Use VerovioTool to render
                        for tool in self.agent.tools:
                            if hasattr(tool, 'render_abc_to_svg'):
                                result = tool.render_abc_to_svg(abc_notation)
                                if "rendered to:" in result:
                                    return result.split("rendered to: ")[1]
                        return None
                    except Exception as e:
                        logger.error(f"Error rendering ABC: {e}")
                        return None
                
                render_btn.click(
                    render_abc,
                    inputs=abc_input,
                    outputs=sheet_output
                )
            
            # Format Conversion
            with gr.Tab("🔄 Format Conversion"):
                gr.Markdown("Convert between different music formats")
                
                input_file = gr.Audio(
                    label="Input File",
                    type="filepath"
                )
                
                target_format = gr.Radio(
                    choices=["ABC", "MIDI", "Audio"],
                    label="Target Format",
                    value="ABC"
                )
                
                convert_btn = gr.Button("Convert", variant="primary")
                
                conversion_output = gr.Textbox(
                    label="Conversion Result",
                    lines=10,
                    interactive=False
                )
                
                def convert_format(input_file, target_format):
                    if self.agent is None:
                        return "Music agent not available"
                    
                    if input_file is None:
                        return "Please upload a file"
                    
                    try:
                        # Use the agent's run method with a prompt for format conversion
                        prompt = f"Please convert this file to {target_format} format. The input file is at: {input_file}"
                        result = self.agent.run(prompt)
                        return result
                    except Exception as e:
                        return f"Error converting format: {str(e)}"
                
                convert_btn.click(
                    convert_format,
                    inputs=[input_file, target_format],
                    outputs=conversion_output
                )
    
    def _create_about_interface(self):
        """Create the about interface."""
        gr.Markdown("""
        # About WeaveMuse

        WeaveMuse is a comprehensive AI-powered system for music understanding, 
        generation, and analysis. It integrates state-of-the-art music AI models with an 
        intelligent agent system built on smolagents.
        
        ## Features
        
        ### 🎼 Music Understanding
        - **ChatMusician Integration**: Natural language music analysis
        - **Music Theory Analysis**: Automatic harmony and structure analysis
        - **Audio Understanding**: Content analysis of audio files
        
        ### 🎵 Music Generation
        - **Symbolic Music**: ABC notation generation using NotaGen
        - **Audio Generation**: High-quality audio synthesis with Stable Audio
        - **Conditional Generation**: Style, composer, and instrumentation control
        
        ### 🤖 Agent Intelligence
        - **Smart Tool Selection**: Automatically chooses the right tools
        - **Multi-modal Input**: Text, audio, and symbolic music
        - **Conversational Interface**: Natural language interaction
        
        ### 🎨 Visualization
        - **Sheet Music Rendering**: Beautiful notation with Verovio
        - **Audio Playback**: Integrated audio player
        - **Analysis Visualizations**: Graphical analysis results
        
        ## Integrated Models
        
        - **ChatMusician**: Music understanding and theory analysis
        - **NotaGen**: Symbolic music generation in ABC notation
        - **Stable Audio Open**: High-quality audio generation
        - **Custom Audio Analysis**: Multi-feature audio understanding
        - **Verovio**: Music notation rendering and visualization
        
        ## Technology Stack
        
        - **Agent Framework**: smolagents
        - **Interface**: Gradio
        - **Models**: Hugging Face Transformers, PyTorch
        - **Music Processing**: librosa, music21, symusic
        - **Deployment**: Docker, FastAPI
        
        ## Getting Started
        
        1. **Chat Interface**: Start with natural language queries
        2. **Generate Music**: Create compositions with specific parameters
        3. **Analyze Audio**: Upload files for detailed analysis
        4. **Use Tools**: Access individual music processing tools
        
        ## Example Uses
        
        - "Compose a peaceful piano piece in C major"
        - "Analyze the harmony in this jazz recording"
        - "Generate ABC notation for a Bach-style fugue"
        - "What's the tempo and key of this song?"
        - "Create sheet music from this melody"
        
        ---
        
        **Built with ❤️ for music and AI**
        """)
        
        # Show available tools
        if self.agent:
            # available_tools = self.agent.get_available_tools()
            # tool_descriptions = self.agent.get_tool_descriptions()
            available_tools = []
            tool_descriptions = {}
            
            gr.Markdown("## Available Tools")
            
            for tool_name in available_tools:
                description = tool_descriptions.get(tool_name, "No description available")
                gr.Markdown(f"### {tool_name}")
                gr.Markdown(f"{description}")
   